{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****Laboratorio 7****\n",
    "### Integrantes:\n",
    "- Pedro Pablo Arriola Jimenez (20188)\n",
    "- Marco Pablo Orozco Saravia (20857)\n",
    "- Santiago Taracena Puga (20017)\n",
    "\n",
    "### Instrucciones:\n",
    "- Deben unirse a uno de los grupos de Canvas de nombre “Laboratorio 7 #”, donde N es un número entre 1 y 23. Los grupos pueden ser de 2 o 3 personas.\n",
    "- Esta actividad debe realizarse en grupos.\n",
    "- Sólo es necesario que una persona del grupo suba el trabajo a Canvas.\n",
    "- No se permitirá ni se aceptará cualquier indicio de copia. De presentarse, se procederá según el reglamento correspondiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Práctica\n",
    "\n",
    "Considere las arquitecturas conversadas durante la clase, con ello realice una implementación de dos arquitecturas usando PyTorch\n",
    "\n",
    "1. Implemente la arquitectura de LeNet-5 para resolver el problema de clasificación del daset de dígitos escritos a mano llamado mnist dataset\n",
    "2. Implemente la arquitectura de AlexNet para resolver el problema de clasificación usando el dataset de imagenes llamado CIFAR10 dataset.\n",
    "\n",
    "Para cada implementación defina y justifique (dentro del notebook) una métrica de desempeño. Además responda (en su notebook), recuerde justificar y/o expandir su respuesta:\n",
    "\n",
    "a. ¿Cuál es la diferencia principal entre ambas arquitecturas?\n",
    "\n",
    "b. ¿Podría usarse LeNet-5 para un problema como el que resolvió usando AlexNet? ¿Y viceversa?\n",
    "\n",
    "c. Indique claramente qué le pareció más interesante de cada arquitectura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 - LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 21206265.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 55313102.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3782652.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4469856.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar y preprocesar el conjunto de datos MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar si CUDA está disponible y configurar el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la arquitectura LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Definir la primera capa convolucional\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Definir la segunda capa convolucional\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Definir las capas completamente conectadas\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Definir la propagación hacia adelante\n",
    "        x = self.pool1(self.act1(self.conv1(x)))\n",
    "        x = self.pool2(self.act2(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = self.act3(self.fc1(x))\n",
    "        x = self.act4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo y moverlo a la GPU si está disponible\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando Época 1...\n",
      "Época [1/10], Paso [100/938], Pérdida: 0.1782\n",
      "Época [1/10], Paso [200/938], Pérdida: 0.0311\n",
      "Época [1/10], Paso [300/938], Pérdida: 0.1647\n",
      "Época [1/10], Paso [400/938], Pérdida: 0.0115\n",
      "Época [1/10], Paso [500/938], Pérdida: 0.1288\n",
      "Época [1/10], Paso [600/938], Pérdida: 0.0251\n",
      "Época [1/10], Paso [700/938], Pérdida: 0.0632\n",
      "Época [1/10], Paso [800/938], Pérdida: 0.0754\n",
      "Época [1/10], Paso [900/938], Pérdida: 0.1118\n",
      "Finalizando Época 1...\n",
      "Comenzando Época 2...\n",
      "Época [2/10], Paso [100/938], Pérdida: 0.0168\n",
      "Época [2/10], Paso [200/938], Pérdida: 0.0056\n",
      "Época [2/10], Paso [300/938], Pérdida: 0.0164\n",
      "Época [2/10], Paso [400/938], Pérdida: 0.0210\n",
      "Época [2/10], Paso [500/938], Pérdida: 0.0415\n",
      "Época [2/10], Paso [600/938], Pérdida: 0.0292\n",
      "Época [2/10], Paso [700/938], Pérdida: 0.1321\n",
      "Época [2/10], Paso [800/938], Pérdida: 0.0453\n",
      "Época [2/10], Paso [900/938], Pérdida: 0.0369\n",
      "Finalizando Época 2...\n",
      "Comenzando Época 3...\n",
      "Época [3/10], Paso [100/938], Pérdida: 0.0136\n",
      "Época [3/10], Paso [200/938], Pérdida: 0.0196\n",
      "Época [3/10], Paso [300/938], Pérdida: 0.0044\n",
      "Época [3/10], Paso [400/938], Pérdida: 0.1001\n",
      "Época [3/10], Paso [500/938], Pérdida: 0.0494\n",
      "Época [3/10], Paso [600/938], Pérdida: 0.0105\n",
      "Época [3/10], Paso [700/938], Pérdida: 0.0892\n",
      "Época [3/10], Paso [800/938], Pérdida: 0.0185\n",
      "Época [3/10], Paso [900/938], Pérdida: 0.1648\n",
      "Finalizando Época 3...\n",
      "Comenzando Época 4...\n",
      "Época [4/10], Paso [100/938], Pérdida: 0.0031\n",
      "Época [4/10], Paso [200/938], Pérdida: 0.0157\n",
      "Época [4/10], Paso [300/938], Pérdida: 0.0139\n",
      "Época [4/10], Paso [400/938], Pérdida: 0.0186\n",
      "Época [4/10], Paso [500/938], Pérdida: 0.0085\n",
      "Época [4/10], Paso [600/938], Pérdida: 0.0957\n",
      "Época [4/10], Paso [700/938], Pérdida: 0.0028\n",
      "Época [4/10], Paso [800/938], Pérdida: 0.1318\n",
      "Época [4/10], Paso [900/938], Pérdida: 0.0503\n",
      "Finalizando Época 4...\n",
      "Comenzando Época 5...\n",
      "Época [5/10], Paso [100/938], Pérdida: 0.0035\n",
      "Época [5/10], Paso [200/938], Pérdida: 0.0056\n",
      "Época [5/10], Paso [300/938], Pérdida: 0.0306\n",
      "Época [5/10], Paso [400/938], Pérdida: 0.0037\n",
      "Época [5/10], Paso [500/938], Pérdida: 0.0071\n",
      "Época [5/10], Paso [600/938], Pérdida: 0.0133\n",
      "Época [5/10], Paso [700/938], Pérdida: 0.1356\n",
      "Época [5/10], Paso [800/938], Pérdida: 0.0475\n",
      "Época [5/10], Paso [900/938], Pérdida: 0.0053\n",
      "Finalizando Época 5...\n",
      "Comenzando Época 6...\n",
      "Época [6/10], Paso [100/938], Pérdida: 0.0017\n",
      "Época [6/10], Paso [200/938], Pérdida: 0.0438\n",
      "Época [6/10], Paso [300/938], Pérdida: 0.0156\n",
      "Época [6/10], Paso [400/938], Pérdida: 0.0260\n",
      "Época [6/10], Paso [500/938], Pérdida: 0.0120\n",
      "Época [6/10], Paso [600/938], Pérdida: 0.0194\n",
      "Época [6/10], Paso [700/938], Pérdida: 0.0431\n",
      "Época [6/10], Paso [800/938], Pérdida: 0.0112\n",
      "Época [6/10], Paso [900/938], Pérdida: 0.0469\n",
      "Finalizando Época 6...\n",
      "Comenzando Época 7...\n",
      "Época [7/10], Paso [100/938], Pérdida: 0.0354\n",
      "Época [7/10], Paso [200/938], Pérdida: 0.0187\n",
      "Época [7/10], Paso [300/938], Pérdida: 0.0087\n",
      "Época [7/10], Paso [400/938], Pérdida: 0.0076\n",
      "Época [7/10], Paso [500/938], Pérdida: 0.0319\n",
      "Época [7/10], Paso [600/938], Pérdida: 0.0009\n",
      "Época [7/10], Paso [700/938], Pérdida: 0.0411\n",
      "Época [7/10], Paso [800/938], Pérdida: 0.0042\n",
      "Época [7/10], Paso [900/938], Pérdida: 0.0021\n",
      "Finalizando Época 7...\n",
      "Comenzando Época 8...\n",
      "Época [8/10], Paso [100/938], Pérdida: 0.0009\n",
      "Época [8/10], Paso [200/938], Pérdida: 0.0036\n",
      "Época [8/10], Paso [300/938], Pérdida: 0.0031\n",
      "Época [8/10], Paso [400/938], Pérdida: 0.0005\n",
      "Época [8/10], Paso [500/938], Pérdida: 0.0040\n",
      "Época [8/10], Paso [600/938], Pérdida: 0.0040\n",
      "Época [8/10], Paso [700/938], Pérdida: 0.0052\n",
      "Época [8/10], Paso [800/938], Pérdida: 0.0060\n",
      "Época [8/10], Paso [900/938], Pérdida: 0.0114\n",
      "Finalizando Época 8...\n",
      "Comenzando Época 9...\n",
      "Época [9/10], Paso [100/938], Pérdida: 0.0958\n",
      "Época [9/10], Paso [200/938], Pérdida: 0.0033\n",
      "Época [9/10], Paso [300/938], Pérdida: 0.0039\n",
      "Época [9/10], Paso [400/938], Pérdida: 0.0294\n",
      "Época [9/10], Paso [500/938], Pérdida: 0.0036\n",
      "Época [9/10], Paso [600/938], Pérdida: 0.0078\n",
      "Época [9/10], Paso [700/938], Pérdida: 0.0156\n",
      "Época [9/10], Paso [800/938], Pérdida: 0.0078\n",
      "Época [9/10], Paso [900/938], Pérdida: 0.0571\n",
      "Finalizando Época 9...\n",
      "Comenzando Época 10...\n",
      "Época [10/10], Paso [100/938], Pérdida: 0.0328\n",
      "Época [10/10], Paso [200/938], Pérdida: 0.0002\n",
      "Época [10/10], Paso [300/938], Pérdida: 0.0619\n",
      "Época [10/10], Paso [400/938], Pérdida: 0.0023\n",
      "Época [10/10], Paso [500/938], Pérdida: 0.0037\n",
      "Época [10/10], Paso [600/938], Pérdida: 0.0105\n",
      "Época [10/10], Paso [700/938], Pérdida: 0.0302\n",
      "Época [10/10], Paso [800/938], Pérdida: 0.0055\n",
      "Época [10/10], Paso [900/938], Pérdida: 0.0235\n",
      "Finalizando Época 10...\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "for epoch in range(10):\n",
    "    print(f\"Comenzando Época {epoch+1}...\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Época [{epoch+1}/{10}], Paso [{batch_idx+1}/{len(train_loader)}], Pérdida: {loss.item():.4f}\")\n",
    "    \n",
    "    print(f\"Finalizando Época {epoch+1}...\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), \"lenet5_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las métricas\n",
    "def calculate_metrics(target, pred):\n",
    "    precision = precision_score(target, pred, average='macro')\n",
    "    recall = recall_score(target, pred, average='macro')\n",
    "    f1 = f1_score(target, pred, average='macro')\n",
    "    confusion = confusion_matrix(target, pred)\n",
    "    return precision, recall, f1, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de Evaluación:\n",
      "Accuracy: 98.55%\n",
      "Precision: 98.56%\n",
      "Recall: 98.53%\n",
      "F1-Score: 98.54%\n",
      "Confusion Matrix: \n",
      "[[ 973    0    0    0    0    0    1    2    2    2]\n",
      " [   1 1130    1    0    0    0    1    1    1    0]\n",
      " [   4    1 1016    0    1    0    0    7    2    1]\n",
      " [   0    0    1  990    0    4    0    8    1    6]\n",
      " [   0    0    0    0  969    0    0    1    0   12]\n",
      " [   4    0    0    3    1  872    4    2    3    3]\n",
      " [   7    4    1    1    2    0  939    0    3    1]\n",
      " [   0    4    4    0    0    0    0 1017    1    2]\n",
      " [   4    0    1    4    0    2    0    3  958    2]\n",
      " [   1    2    0    0    5    3    0    6    1  991]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado\n",
    "model = LeNet5().to(device)\n",
    "model.load_state_dict(torch.load(\"lenet5_mnist.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Inicializar listas para predicciones y etiquetas verdaderas\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# Realizar la evaluación\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "# Calcular y mostrar las métricas\n",
    "precision, recall, f1, confusion = calculate_metrics(all_targets, all_preds)\n",
    "accuracy = sum(p == t for p, t in zip(all_preds, all_targets)) / len(all_targets)\n",
    "print(f\"Resumen de Evaluación:\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1-Score: {f1:.2%}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 - AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:12<00:00, 13836647.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Cambiar el tamaño de las imágenes a 224x224 para AlexNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        # Definir la parte de características (convoluciones)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        # Añadir una capa de agrupamiento adaptativo\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        # Definir la parte clasificadora (fully connected)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Definir la propagación hacia adelante\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo, definir la función de pérdida y el optimizador\n",
    "model = AlexNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando Época 1...\n",
      "Época [1/10], Paso [100/782], Pérdida: 1.9219\n",
      "Época [1/10], Paso [200/782], Pérdida: 1.7619\n",
      "Época [1/10], Paso [300/782], Pérdida: 1.7739\n",
      "Época [1/10], Paso [400/782], Pérdida: 1.7023\n",
      "Época [1/10], Paso [500/782], Pérdida: 1.5121\n",
      "Época [1/10], Paso [600/782], Pérdida: 1.6206\n",
      "Época [1/10], Paso [700/782], Pérdida: 1.5066\n",
      "Finalizando Época 1...\n",
      "Comenzando Época 2...\n",
      "Época [2/10], Paso [100/782], Pérdida: 1.5378\n",
      "Época [2/10], Paso [200/782], Pérdida: 1.2569\n",
      "Época [2/10], Paso [300/782], Pérdida: 1.4204\n",
      "Época [2/10], Paso [400/782], Pérdida: 1.2387\n",
      "Época [2/10], Paso [500/782], Pérdida: 1.5373\n",
      "Época [2/10], Paso [600/782], Pérdida: 1.2811\n",
      "Época [2/10], Paso [700/782], Pérdida: 1.2991\n",
      "Finalizando Época 2...\n",
      "Comenzando Época 3...\n",
      "Época [3/10], Paso [100/782], Pérdida: 1.3004\n",
      "Época [3/10], Paso [200/782], Pérdida: 1.3912\n",
      "Época [3/10], Paso [300/782], Pérdida: 1.1083\n",
      "Época [3/10], Paso [400/782], Pérdida: 1.1085\n",
      "Época [3/10], Paso [500/782], Pérdida: 1.1752\n",
      "Época [3/10], Paso [600/782], Pérdida: 1.3403\n",
      "Época [3/10], Paso [700/782], Pérdida: 1.1676\n",
      "Finalizando Época 3...\n",
      "Comenzando Época 4...\n",
      "Época [4/10], Paso [100/782], Pérdida: 0.9418\n",
      "Época [4/10], Paso [200/782], Pérdida: 0.9658\n",
      "Época [4/10], Paso [300/782], Pérdida: 1.3981\n",
      "Época [4/10], Paso [400/782], Pérdida: 0.8492\n",
      "Época [4/10], Paso [500/782], Pérdida: 1.1591\n",
      "Época [4/10], Paso [600/782], Pérdida: 1.0892\n",
      "Época [4/10], Paso [700/782], Pérdida: 1.0778\n",
      "Finalizando Época 4...\n",
      "Comenzando Época 5...\n",
      "Época [5/10], Paso [100/782], Pérdida: 1.0427\n",
      "Época [5/10], Paso [200/782], Pérdida: 0.8559\n",
      "Época [5/10], Paso [300/782], Pérdida: 1.0726\n",
      "Época [5/10], Paso [400/782], Pérdida: 0.8978\n",
      "Época [5/10], Paso [500/782], Pérdida: 1.3162\n",
      "Época [5/10], Paso [600/782], Pérdida: 1.2437\n",
      "Época [5/10], Paso [700/782], Pérdida: 1.1687\n",
      "Finalizando Época 5...\n",
      "Comenzando Época 6...\n",
      "Época [6/10], Paso [100/782], Pérdida: 1.0976\n",
      "Época [6/10], Paso [200/782], Pérdida: 0.9465\n",
      "Época [6/10], Paso [300/782], Pérdida: 1.0014\n",
      "Época [6/10], Paso [400/782], Pérdida: 0.8219\n",
      "Época [6/10], Paso [500/782], Pérdida: 1.0052\n",
      "Época [6/10], Paso [600/782], Pérdida: 1.1047\n",
      "Época [6/10], Paso [700/782], Pérdida: 0.8578\n",
      "Finalizando Época 6...\n",
      "Comenzando Época 7...\n",
      "Época [7/10], Paso [100/782], Pérdida: 0.7804\n",
      "Época [7/10], Paso [200/782], Pérdida: 1.0167\n",
      "Época [7/10], Paso [300/782], Pérdida: 0.7903\n",
      "Época [7/10], Paso [400/782], Pérdida: 0.8881\n",
      "Época [7/10], Paso [500/782], Pérdida: 0.9687\n",
      "Época [7/10], Paso [600/782], Pérdida: 0.7294\n",
      "Época [7/10], Paso [700/782], Pérdida: 0.7307\n",
      "Finalizando Época 7...\n",
      "Comenzando Época 8...\n",
      "Época [8/10], Paso [100/782], Pérdida: 0.6327\n",
      "Época [8/10], Paso [200/782], Pérdida: 0.8548\n",
      "Época [8/10], Paso [300/782], Pérdida: 0.6528\n",
      "Época [8/10], Paso [400/782], Pérdida: 0.8841\n",
      "Época [8/10], Paso [500/782], Pérdida: 0.7829\n",
      "Época [8/10], Paso [600/782], Pérdida: 0.9647\n",
      "Época [8/10], Paso [700/782], Pérdida: 0.6751\n",
      "Finalizando Época 8...\n",
      "Comenzando Época 9...\n",
      "Época [9/10], Paso [100/782], Pérdida: 0.7758\n",
      "Época [9/10], Paso [200/782], Pérdida: 1.0283\n",
      "Época [9/10], Paso [300/782], Pérdida: 0.7019\n",
      "Época [9/10], Paso [400/782], Pérdida: 0.7256\n",
      "Época [9/10], Paso [500/782], Pérdida: 0.6950\n",
      "Época [9/10], Paso [600/782], Pérdida: 1.0103\n",
      "Época [9/10], Paso [700/782], Pérdida: 0.9145\n",
      "Finalizando Época 9...\n",
      "Comenzando Época 10...\n",
      "Época [10/10], Paso [100/782], Pérdida: 0.7479\n",
      "Época [10/10], Paso [200/782], Pérdida: 1.0873\n",
      "Época [10/10], Paso [300/782], Pérdida: 1.0165\n",
      "Época [10/10], Paso [400/782], Pérdida: 0.8789\n",
      "Época [10/10], Paso [500/782], Pérdida: 0.8474\n",
      "Época [10/10], Paso [600/782], Pérdida: 0.7214\n",
      "Época [10/10], Paso [700/782], Pérdida: 0.6975\n",
      "Finalizando Época 10...\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "for epoch in range(10):\n",
    "    print(f\"Comenzando Época {epoch+1}...\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Época [{epoch+1}/{10}], Paso [{batch_idx+1}/{len(train_loader)}], Pérdida: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Finalizando Época {epoch+1}...\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), \"alexnet_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de Evaluación:\n",
      "Accuracy: 69.69%\n",
      "Precision: 71.57%\n",
      "Recall: 69.69%\n",
      "F1-Score: 69.68%\n",
      "Confusion Matrix: \n",
      "[[703  16  78  30  22   2  16   7  97  29]\n",
      " [ 10 821  11   7   6   2  15   1  23 104]\n",
      " [ 45   3 663  77  68  18  98   9  10   9]\n",
      " [ 15   5  89 619  51  49 107  21  19  25]\n",
      " [  9   5 130  63 621  16 113  35   7   1]\n",
      " [  8   4  93 321  59 418  55  23  10   9]\n",
      " [  4   0  40  47  26   7 868   1   4   3]\n",
      " [ 13   1  77  80  88  30  20 672   2  17]\n",
      " [ 63  25  22  19   5   1  25   4 801  35]\n",
      " [ 26  85  12  27   9   2  17  13  26 783]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado\n",
    "model = AlexNet().to(device)\n",
    "model.load_state_dict(torch.load(\"alexnet_cifar10.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Inicializar listas para predicciones y etiquetas verdaderas\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# Realizar la evaluación\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "# Calcular y mostrar las métricas\n",
    "precision, recall, f1, confusion = calculate_metrics(all_targets, all_preds)\n",
    "accuracy = sum(p == t for p, t in zip(all_preds, all_targets)) / len(all_targets)\n",
    "print(f\"Resumen de Evaluación:\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1-Score: {f1:.2%}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Teoría\n",
    "Responda claramente y con una extensión adecuada las siguientes preguntas:\n",
    "1. Investigue e indique en qué casos son útiles las siguientes arquitecturas, agregue imagenes si esto le ayuda a una mejor comprensión\n",
    "\n",
    "- GoogleNet (Inception)\n",
    "\n",
    "- DenseNet (Densely Connected Convolutional Networks)\n",
    "\n",
    "- MobileNet\n",
    "\n",
    "-  EfficientNet\n",
    "\n",
    "2. ¿Cómo la arquitectura de transformers puede ser usada para image recognition?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
