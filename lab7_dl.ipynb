{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ****Laboratorio 7****\n",
    "### Integrantes:\n",
    "- Pedro Pablo Arriola Jimenez (20188)\n",
    "- Marco Pablo Orozco Saravia (20857)\n",
    "- Santiago Taracena Puga (20017)\n",
    "\n",
    "### Instrucciones:\n",
    "- Deben unirse a uno de los grupos de Canvas de nombre “Laboratorio 7 #”, donde N es un número entre 1 y 23. Los grupos pueden ser de 2 o 3 personas.\n",
    "- Esta actividad debe realizarse en grupos.\n",
    "- Sólo es necesario que una persona del grupo suba el trabajo a Canvas.\n",
    "- No se permitirá ni se aceptará cualquier indicio de copia. De presentarse, se procederá según el reglamento correspondiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Práctica\n",
    "\n",
    "Considere las arquitecturas conversadas durante la clase, con ello realice una implementación de dos arquitecturas usando PyTorch\n",
    "\n",
    "1. Implemente la arquitectura de LeNet-5 para resolver el problema de clasificación del daset de dígitos escritos a mano llamado mnist dataset\n",
    "2. Implemente la arquitectura de AlexNet para resolver el problema de clasificación usando el dataset de imagenes llamado CIFAR10 dataset.\n",
    "\n",
    "Para cada implementación defina y justifique (dentro del notebook) una métrica de desempeño. Además responda (en su notebook), recuerde justificar y/o expandir su respuesta:\n",
    "\n",
    "a. ¿Cuál es la diferencia principal entre ambas arquitecturas?\n",
    "\n",
    "b. ¿Podría usarse LeNet-5 para un problema como el que resolvió usando AlexNet? ¿Y viceversa?\n",
    "\n",
    "c. Indique claramente qué le pareció más interesante de cada arquitectura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 - LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 21206265.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 55313102.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3782652.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4469856.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar y preprocesar el conjunto de datos MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar si CUDA está disponible y configurar el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la arquitectura LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Definir la primera capa convolucional\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Definir la segunda capa convolucional\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Definir las capas completamente conectadas\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Definir la propagación hacia adelante\n",
    "        x = self.pool1(self.act1(self.conv1(x)))\n",
    "        x = self.pool2(self.act2(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = self.act3(self.fc1(x))\n",
    "        x = self.act4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo y moverlo a la GPU si está disponible\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando Época 1...\n",
      "Época [1/10], Paso [100/938], Pérdida: 0.1782\n",
      "Época [1/10], Paso [200/938], Pérdida: 0.0311\n",
      "Época [1/10], Paso [300/938], Pérdida: 0.1647\n",
      "Época [1/10], Paso [400/938], Pérdida: 0.0115\n",
      "Época [1/10], Paso [500/938], Pérdida: 0.1288\n",
      "Época [1/10], Paso [600/938], Pérdida: 0.0251\n",
      "Época [1/10], Paso [700/938], Pérdida: 0.0632\n",
      "Época [1/10], Paso [800/938], Pérdida: 0.0754\n",
      "Época [1/10], Paso [900/938], Pérdida: 0.1118\n",
      "Finalizando Época 1...\n",
      "Comenzando Época 2...\n",
      "Época [2/10], Paso [100/938], Pérdida: 0.0168\n",
      "Época [2/10], Paso [200/938], Pérdida: 0.0056\n",
      "Época [2/10], Paso [300/938], Pérdida: 0.0164\n",
      "Época [2/10], Paso [400/938], Pérdida: 0.0210\n",
      "Época [2/10], Paso [500/938], Pérdida: 0.0415\n",
      "Época [2/10], Paso [600/938], Pérdida: 0.0292\n",
      "Época [2/10], Paso [700/938], Pérdida: 0.1321\n",
      "Época [2/10], Paso [800/938], Pérdida: 0.0453\n",
      "Época [2/10], Paso [900/938], Pérdida: 0.0369\n",
      "Finalizando Época 2...\n",
      "Comenzando Época 3...\n",
      "Época [3/10], Paso [100/938], Pérdida: 0.0136\n",
      "Época [3/10], Paso [200/938], Pérdida: 0.0196\n",
      "Época [3/10], Paso [300/938], Pérdida: 0.0044\n",
      "Época [3/10], Paso [400/938], Pérdida: 0.1001\n",
      "Época [3/10], Paso [500/938], Pérdida: 0.0494\n",
      "Época [3/10], Paso [600/938], Pérdida: 0.0105\n",
      "Época [3/10], Paso [700/938], Pérdida: 0.0892\n",
      "Época [3/10], Paso [800/938], Pérdida: 0.0185\n",
      "Época [3/10], Paso [900/938], Pérdida: 0.1648\n",
      "Finalizando Época 3...\n",
      "Comenzando Época 4...\n",
      "Época [4/10], Paso [100/938], Pérdida: 0.0031\n",
      "Época [4/10], Paso [200/938], Pérdida: 0.0157\n",
      "Época [4/10], Paso [300/938], Pérdida: 0.0139\n",
      "Época [4/10], Paso [400/938], Pérdida: 0.0186\n",
      "Época [4/10], Paso [500/938], Pérdida: 0.0085\n",
      "Época [4/10], Paso [600/938], Pérdida: 0.0957\n",
      "Época [4/10], Paso [700/938], Pérdida: 0.0028\n",
      "Época [4/10], Paso [800/938], Pérdida: 0.1318\n",
      "Época [4/10], Paso [900/938], Pérdida: 0.0503\n",
      "Finalizando Época 4...\n",
      "Comenzando Época 5...\n",
      "Época [5/10], Paso [100/938], Pérdida: 0.0035\n",
      "Época [5/10], Paso [200/938], Pérdida: 0.0056\n",
      "Época [5/10], Paso [300/938], Pérdida: 0.0306\n",
      "Época [5/10], Paso [400/938], Pérdida: 0.0037\n",
      "Época [5/10], Paso [500/938], Pérdida: 0.0071\n",
      "Época [5/10], Paso [600/938], Pérdida: 0.0133\n",
      "Época [5/10], Paso [700/938], Pérdida: 0.1356\n",
      "Época [5/10], Paso [800/938], Pérdida: 0.0475\n",
      "Época [5/10], Paso [900/938], Pérdida: 0.0053\n",
      "Finalizando Época 5...\n",
      "Comenzando Época 6...\n",
      "Época [6/10], Paso [100/938], Pérdida: 0.0017\n",
      "Época [6/10], Paso [200/938], Pérdida: 0.0438\n",
      "Época [6/10], Paso [300/938], Pérdida: 0.0156\n",
      "Época [6/10], Paso [400/938], Pérdida: 0.0260\n",
      "Época [6/10], Paso [500/938], Pérdida: 0.0120\n",
      "Época [6/10], Paso [600/938], Pérdida: 0.0194\n",
      "Época [6/10], Paso [700/938], Pérdida: 0.0431\n",
      "Época [6/10], Paso [800/938], Pérdida: 0.0112\n",
      "Época [6/10], Paso [900/938], Pérdida: 0.0469\n",
      "Finalizando Época 6...\n",
      "Comenzando Época 7...\n",
      "Época [7/10], Paso [100/938], Pérdida: 0.0354\n",
      "Época [7/10], Paso [200/938], Pérdida: 0.0187\n",
      "Época [7/10], Paso [300/938], Pérdida: 0.0087\n",
      "Época [7/10], Paso [400/938], Pérdida: 0.0076\n",
      "Época [7/10], Paso [500/938], Pérdida: 0.0319\n",
      "Época [7/10], Paso [600/938], Pérdida: 0.0009\n",
      "Época [7/10], Paso [700/938], Pérdida: 0.0411\n",
      "Época [7/10], Paso [800/938], Pérdida: 0.0042\n",
      "Época [7/10], Paso [900/938], Pérdida: 0.0021\n",
      "Finalizando Época 7...\n",
      "Comenzando Época 8...\n",
      "Época [8/10], Paso [100/938], Pérdida: 0.0009\n",
      "Época [8/10], Paso [200/938], Pérdida: 0.0036\n",
      "Época [8/10], Paso [300/938], Pérdida: 0.0031\n",
      "Época [8/10], Paso [400/938], Pérdida: 0.0005\n",
      "Época [8/10], Paso [500/938], Pérdida: 0.0040\n",
      "Época [8/10], Paso [600/938], Pérdida: 0.0040\n",
      "Época [8/10], Paso [700/938], Pérdida: 0.0052\n",
      "Época [8/10], Paso [800/938], Pérdida: 0.0060\n",
      "Época [8/10], Paso [900/938], Pérdida: 0.0114\n",
      "Finalizando Época 8...\n",
      "Comenzando Época 9...\n",
      "Época [9/10], Paso [100/938], Pérdida: 0.0958\n",
      "Época [9/10], Paso [200/938], Pérdida: 0.0033\n",
      "Época [9/10], Paso [300/938], Pérdida: 0.0039\n",
      "Época [9/10], Paso [400/938], Pérdida: 0.0294\n",
      "Época [9/10], Paso [500/938], Pérdida: 0.0036\n",
      "Época [9/10], Paso [600/938], Pérdida: 0.0078\n",
      "Época [9/10], Paso [700/938], Pérdida: 0.0156\n",
      "Época [9/10], Paso [800/938], Pérdida: 0.0078\n",
      "Época [9/10], Paso [900/938], Pérdida: 0.0571\n",
      "Finalizando Época 9...\n",
      "Comenzando Época 10...\n",
      "Época [10/10], Paso [100/938], Pérdida: 0.0328\n",
      "Época [10/10], Paso [200/938], Pérdida: 0.0002\n",
      "Época [10/10], Paso [300/938], Pérdida: 0.0619\n",
      "Época [10/10], Paso [400/938], Pérdida: 0.0023\n",
      "Época [10/10], Paso [500/938], Pérdida: 0.0037\n",
      "Época [10/10], Paso [600/938], Pérdida: 0.0105\n",
      "Época [10/10], Paso [700/938], Pérdida: 0.0302\n",
      "Época [10/10], Paso [800/938], Pérdida: 0.0055\n",
      "Época [10/10], Paso [900/938], Pérdida: 0.0235\n",
      "Finalizando Época 10...\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "for epoch in range(10):\n",
    "    print(f\"Comenzando Época {epoch+1}...\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Época [{epoch+1}/{10}], Paso [{batch_idx+1}/{len(train_loader)}], Pérdida: {loss.item():.4f}\")\n",
    "    \n",
    "    print(f\"Finalizando Época {epoch+1}...\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), \"lenet5_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las métricas\n",
    "def calculate_metrics(target, pred):\n",
    "    precision = precision_score(target, pred, average='macro')\n",
    "    recall = recall_score(target, pred, average='macro')\n",
    "    f1 = f1_score(target, pred, average='macro')\n",
    "    confusion = confusion_matrix(target, pred)\n",
    "    return precision, recall, f1, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de Evaluación:\n",
      "Accuracy: 98.55%\n",
      "Precision: 98.56%\n",
      "Recall: 98.53%\n",
      "F1-Score: 98.54%\n",
      "Confusion Matrix: \n",
      "[[ 973    0    0    0    0    0    1    2    2    2]\n",
      " [   1 1130    1    0    0    0    1    1    1    0]\n",
      " [   4    1 1016    0    1    0    0    7    2    1]\n",
      " [   0    0    1  990    0    4    0    8    1    6]\n",
      " [   0    0    0    0  969    0    0    1    0   12]\n",
      " [   4    0    0    3    1  872    4    2    3    3]\n",
      " [   7    4    1    1    2    0  939    0    3    1]\n",
      " [   0    4    4    0    0    0    0 1017    1    2]\n",
      " [   4    0    1    4    0    2    0    3  958    2]\n",
      " [   1    2    0    0    5    3    0    6    1  991]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado\n",
    "model = LeNet5().to(device)\n",
    "model.load_state_dict(torch.load(\"lenet5_mnist.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Inicializar listas para predicciones y etiquetas verdaderas\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# Realizar la evaluación\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True).squeeze()\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "# Calcular y mostrar las métricas\n",
    "precision, recall, f1, confusion = calculate_metrics(all_targets, all_preds)\n",
    "accuracy = sum(p == t for p, t in zip(all_preds, all_targets)) / len(all_targets)\n",
    "print(f\"Resumen de Evaluación:\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1-Score: {f1:.2%}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 - AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Teoría\n",
    "Responda claramente y con una extensión adecuada las siguientes preguntas:\n",
    "1. Investigue e indique en qué casos son útiles las siguientes arquitecturas, agregue imagenes si esto le ayuda a una mejor comprensión\n",
    "\n",
    "- GoogleNet (Inception)\n",
    "\n",
    "- DenseNet (Densely Connected Convolutional Networks)\n",
    "\n",
    "- MobileNet\n",
    "\n",
    "-  EfficientNet\n",
    "\n",
    "2. ¿Cómo la arquitectura de transformers puede ser usada para image recognition?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
